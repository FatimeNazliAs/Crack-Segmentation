{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport cv2\nfrom glob import glob\nfrom PIL import Image\nimport random\n\n","metadata":{"id":"55eiYbkqz1uF","execution":{"iopub.status.busy":"2022-04-28T10:49:31.535641Z","iopub.execute_input":"2022-04-28T10:49:31.536202Z","iopub.status.idle":"2022-04-28T10:49:31.541376Z","shell.execute_reply.started":"2022-04-28T10:49:31.536163Z","shell.execute_reply":"2022-04-28T10:49:31.540525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#EXPERIMENTAL BLOCK\nfrom keras import backend as K\n# jaccard similarity: the size of the intersection divided by the size of the union of two sets\ndef jaccard_index(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return 1 - ((intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0))\n\ndef dice_coeff(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    \n    return (2.0 * intersection + 1e-6) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1e-6)\n\ndef dice_loss(y_true, y_pred):\n    coeff = dice_coeff(y_true, y_pred)\n    return 1-coeff","metadata":{"execution":{"iopub.status.busy":"2022-04-28T10:49:31.548452Z","iopub.execute_input":"2022-04-28T10:49:31.548679Z","iopub.status.idle":"2022-04-28T10:49:31.558415Z","shell.execute_reply.started":"2022-04-28T10:49:31.548652Z","shell.execute_reply":"2022-04-28T10:49:31.557506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ndata_gen_args = dict(\n                     rescale=1./255,\n                     rotation_range=90,\n                     width_shift_range=0.1,\n                     height_shift_range=0.1,\n                     zoom_range=0.2)\nimage_datagen = ImageDataGenerator(**data_gen_args)\nmask_datagen = ImageDataGenerator(**data_gen_args)\n\nseed = 1\n\n\nimage_generator = image_datagen.flow_from_directory(\n    '../input/finalcrack/final crack/train/images',\n    class_mode=None,\n    color_mode='rgb',\n    target_size=(224,224),\n    batch_size=10,\n    seed=seed)\nmask_generator = mask_datagen.flow_from_directory(\n    '../input/finalcrack/final crack/train/masks',\n    class_mode=None,\n    color_mode='grayscale',\n    target_size=(224,224),\n    batch_size=10,\n    seed=seed)\n\ntrain_generator = zip(image_generator, mask_generator)\n","metadata":{"id":"Wi1wk0DSz1uK","outputId":"8a6c41d2-91ec-4f41-9f0c-fd5f8577ae89","execution":{"iopub.status.busy":"2022-04-28T10:49:31.560579Z","iopub.execute_input":"2022-04-28T10:49:31.561101Z","iopub.status.idle":"2022-04-28T10:49:35.42233Z","shell.execute_reply.started":"2022-04-28T10:49:31.561062Z","shell.execute_reply":"2022-04-28T10:49:35.42158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_datagen = ImageDataGenerator(**data_gen_args)\nmask_datagen = ImageDataGenerator(**data_gen_args)\n\nseed = 1\n\nimage_generator = image_datagen.flow_from_directory(\n    '../input/finalcrack/final crack/test/images',\n    class_mode=None,\n    color_mode='rgb',\n    target_size=(224,224),\n    batch_size=10,\n    seed=seed)\nmask_generator = mask_datagen.flow_from_directory(\n    '../input/finalcrack/final crack/test/masks',\n    class_mode=None,\n    color_mode='grayscale',\n    target_size=(224,224),\n    batch_size=10,\n    seed=seed)\n\ntest_generator = zip(image_generator, mask_generator)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T10:49:35.423642Z","iopub.execute_input":"2022-04-28T10:49:35.424091Z","iopub.status.idle":"2022-04-28T10:49:35.998858Z","shell.execute_reply.started":"2022-04-28T10:49:35.424052Z","shell.execute_reply":"2022-04-28T10:49:35.997407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def double_conv_block(x,n_filters):\n    \n    x=layers.Conv2D(n_filters,3,padding=\"same\",activation=\"relu\",kernel_initializer=\"he_normal\")(x)\n    x=layers.Conv2D(n_filters,3,padding=\"same\",activation=\"relu\",kernel_initializer=\"he_normal\")(x)\n    return x\n\n\ndef upsample_block(x,conv_features,n_filters):\n    \n    \n    \n    x=layers.Conv2DTranspose(n_filters,3,2,padding=\"same\")(x)\n    x=layers.concatenate([x,conv_features])\n    x=layers.Dropout(0.3)(x)\n    x=double_conv_block(x,n_filters)\n    return x","metadata":{"id":"UXKR82tLz1uL","execution":{"iopub.status.busy":"2022-04-28T10:49:36.000564Z","iopub.execute_input":"2022-04-28T10:49:36.0009Z","iopub.status.idle":"2022-04-28T10:49:36.007277Z","shell.execute_reply.started":"2022-04-28T10:49:36.000864Z","shell.execute_reply":"2022-04-28T10:49:36.006607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_unet_model():\n\n    inputs=layers.Input(shape=(224,224,3))\n    encoder = keras.applications.VGG16(include_top=False, weights=\"imagenet\", input_shape=(224,224,3),input_tensor=inputs)\n\n    f1 = encoder.get_layer('block1_conv2').output\n    f2 = encoder.get_layer('block2_conv2').output\n    f3 = encoder.get_layer('block3_conv3').output\n    f4 = encoder.get_layer('block4_conv3').output\n\n\n    bottleneck = encoder.get_layer('block5_conv3').output\n\n\n    u6=upsample_block(bottleneck,f4,512)\n    u7=upsample_block(u6,f3,256)\n    u8=upsample_block(u7,f2,128)\n    u9=upsample_block(u8,f1,64)\n\n    outputs=layers.Conv2D(1,1,padding=\"same\",activation=\"sigmoid\")(u9)\n    print(outputs.shape)\n\n    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n\n    return unet_model\n\n\n","metadata":{"id":"g04w-RW1z1uM","execution":{"iopub.status.busy":"2022-04-28T10:49:36.009828Z","iopub.execute_input":"2022-04-28T10:49:36.010336Z","iopub.status.idle":"2022-04-28T10:49:36.019581Z","shell.execute_reply.started":"2022-04-28T10:49:36.010299Z","shell.execute_reply":"2022-04-28T10:49:36.018695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet_model = build_unet_model()\n\nad=tf.keras.optimizers.Adam(\n    learning_rate=0.0001,\n    beta_1=0.9,\n    beta_2=0.999,\n    epsilon=1e-07,\n    amsgrad=False,\n    name=\"Adam\")\n                \nmodel = build_unet_model()\nmodel.compile(optimizer=ad,\n                  loss=dice_loss,\n                  metrics=['accuracy'] )\nmodel_history=model.fit(train_generator,steps_per_epoch=300,epochs=10,validation_data=test_generator,validation_steps=30)\nmodel.save('unet3')","metadata":{"id":"E0KozJj7sYgv","outputId":"2b98b270-2af9-4d87-c392-3af481142bd7","execution":{"iopub.status.busy":"2022-04-28T10:49:36.021215Z","iopub.execute_input":"2022-04-28T10:49:36.022062Z","iopub.status.idle":"2022-04-28T11:05:01.416288Z","shell.execute_reply.started":"2022-04-28T10:49:36.022022Z","shell.execute_reply":"2022-04-28T11:05:01.415476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = cv2.imread(\"../input/asdfasdf/crack_in_large_context_04.jpeg\", cv2.IMREAD_COLOR)\nimage = cv2.resize(image, (224, 224),interpolation=cv2.INTER_AREA)\nplt.subplot(1,2,1)\nplt.imshow(image)\nimage = tf.cast(image, tf.float32) / 255.0\nimage = np.expand_dims(image,axis=0)\nlast = model.predict(image)[0,:,:,0]\nprint(last)\nplt.subplot(1,2,2)\nplt.imshow(last) ","metadata":{"execution":{"iopub.status.busy":"2022-04-28T11:05:01.419601Z","iopub.execute_input":"2022-04-28T11:05:01.420323Z","iopub.status.idle":"2022-04-28T11:05:02.010299Z","shell.execute_reply.started":"2022-04-28T11:05:01.42028Z","shell.execute_reply":"2022-04-28T11:05:02.0096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# b = 190\n# for a in range(b,b+5):\n#     plt.figure(figsize=(10,10))\n#     plt.subplot(1,3,1)\n#     plt.axis(False)\n#     plt.title(\"Original Image\", fontweight=\"bold\")\n    \n#     plt.imshow(x[a])\n#     plt.subplot(1,3,2)\n#     plt.imshow(y[a])\n#     plt.subplot(1,3,3)\n#     plt.axis(False)\n#     plt.title(\"Segmentation Mask\", fontweight=\"bold\")\n#     img = np.expand_dims(x[a],axis=0)\n#     last = unet_model.predict(img)[0,:,:,0]\n#     plt.imshow(last)","metadata":{"id":"AYdRZWKcz1uN","outputId":"35447b5c-ea5e-4156-dbe7-14211262f295","execution":{"iopub.status.busy":"2022-04-28T11:05:02.011651Z","iopub.execute_input":"2022-04-28T11:05:02.01191Z","iopub.status.idle":"2022-04-28T11:05:02.016308Z","shell.execute_reply.started":"2022-04-28T11:05:02.011876Z","shell.execute_reply":"2022-04-28T11:05:02.015679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = model_history.history['loss']\nprint(loss)\n\nval_loss = model_history .history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'y', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nacc = model_history .history['accuracy']\nval_acc = model_history .history['val_accuracy']\nplt.plot(epochs, acc, 'y', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T11:05:02.017779Z","iopub.execute_input":"2022-04-28T11:05:02.018324Z","iopub.status.idle":"2022-04-28T11:05:02.401053Z","shell.execute_reply.started":"2022-04-28T11:05:02.018198Z","shell.execute_reply":"2022-04-28T11:05:02.400369Z"},"trusted":true},"execution_count":null,"outputs":[]}]}