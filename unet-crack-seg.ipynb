{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nazlias/unet-crack-seg?scriptVersionId=94784097\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport cv2\nfrom glob import glob\nfrom PIL import Image\nimport random\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:22:11.664509Z","iopub.execute_input":"2022-04-11T18:22:11.66483Z","iopub.status.idle":"2022-04-11T18:22:17.93436Z","shell.execute_reply.started":"2022-04-11T18:22:11.664749Z","shell.execute_reply":"2022-04-11T18:22:17.933609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**collect()**\n\n\nDataset dataforcrack adlı dosyadaki train ve test dosyalarından elde edilir. Bu dosyalarda images ve masks olmak üzere iki ayrı dosya bulunur.\nCollect fonksiyonu path1 ve path2'de belirtilen dosyalardaki resimleri ve her bir dosyadan alınacak resim sayısını parametre olarak alır. \n\n\nTrain ve test dosyaları için fonksiyon iki kez çalışır.\nImages ve masks dosyalarında bulunan resimler alınarak iki ayrı for döngüsünde imread, resize, cast ve append metodları uygulanarak resimler uygun hale getirilir. Sonrasında image_list ve mask_list olmak üzere iki ayrı listeye kaydedilir.\n","metadata":{}},{"cell_type":"code","source":"def collect(path,low, high):\n    \n    image_list = []\n    mask_list = []\n\n    a = low\n    images=sorted(os.listdir(path + '/images/'))\n    \n    for filename in images:\n        a += 1\n        \n        image = cv2.imread(path + '/images/'+ filename, cv2.IMREAD_COLOR)\n        \n   \n        image = cv2.resize(image, (128, 128),interpolation=cv2.INTER_AREA)\n      \n        image = tf.cast(image, tf.float32) / 255.0\n\n        image_list.append(image)\n    \n   \n        if a == high:\n            break\n\n    a = low\n    masks=sorted(os.listdir(path + '/masks/'))\n    for filename in masks:\n        a += 1\n        mask = cv2.imread(path + '/masks/' +filename,cv2.IMREAD_GRAYSCALE)\n        mask = cv2.resize(mask, (128, 128))\n        mask = np.expand_dims(mask, axis=-1)\n        mask = tf.cast(mask, tf.float32) / 255.0\n        mask_list.append(mask)\n\n        if a == high:\n            break\n\n\n\n\n    return image_list, mask_list","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:22:17.936315Z","iopub.execute_input":"2022-04-11T18:22:17.936558Z","iopub.status.idle":"2022-04-11T18:22:17.94673Z","shell.execute_reply.started":"2022-04-11T18:22:17.936525Z","shell.execute_reply":"2022-04-11T18:22:17.946038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**tf_dataset()**\n\nÇeşitli işlemler uygulandıktan sonra her bir dosya için(train, test) iki ayrı liste bulunur. \nBu listeler tf_dataset() fonksiyonu içerisinde iki ayrı datasete dönüştürülür.(train_dataset, test_dataset)","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import save_img\npath1=\"../input/dataforcrack/crack_segmentation_dataset/train\"\npath2=\"../input/dataforcrack/crack_segmentation_dataset/test\"\nx,y=collect(path1,0,9600)\nz,t=collect(path2,0,1600)\n\"\"\"\nx=tf.keras.utils.save_img(\n    x=x, data_format=None, file_format=None, scale=True,\n)\n\"\"\"\n\n\ndef tf_dataset(X, Y, batch=64):\n    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n\n    dataset = dataset.batch(batch,drop_remainder=True)\n\n    dataset = dataset.prefetch(10)\n\n    return dataset \n\ntrain_dataset = tf_dataset(x,y)\n\ntest_dataset = tf_dataset(z,t)\nprint(train_dataset)\nprint(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:22:17.949862Z","iopub.execute_input":"2022-04-11T18:22:17.950177Z","iopub.status.idle":"2022-04-11T18:27:08.734736Z","shell.execute_reply.started":"2022-04-11T18:22:17.950142Z","shell.execute_reply":"2022-04-11T18:27:08.734009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(x[7])\nprint(plt.show)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:27:08.736828Z","iopub.execute_input":"2022-04-11T18:27:08.737261Z","iopub.status.idle":"2022-04-11T18:27:08.99753Z","shell.execute_reply.started":"2022-04-11T18:27:08.73721Z","shell.execute_reply":"2022-04-11T18:27:08.996826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(y[7])\nprint(y[7][64])","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:27:08.998478Z","iopub.execute_input":"2022-04-11T18:27:08.998728Z","iopub.status.idle":"2022-04-11T18:27:09.206777Z","shell.execute_reply.started":"2022-04-11T18:27:08.998696Z","shell.execute_reply":"2022-04-11T18:27:09.206074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**double_conv_block()**\n\nBu fonksiyon içerisinde U-Net modeli için gereken encode ve decode kısımları oluşturulur. \ndownsample_block() fonksiyonu ile encode, upsample_block() fonksiyonu ile decode oluşturulurken double_conv_block hem encode hem decode kısmında kullanıldığı için ayrı bir fonksiyon olarak yazılmıştır. Aşağıda fonksiyonda verilen parametreler açıklanmıştır.\n\nn_filters-> filtre sayısı\n\nkernel_initalizer->Çekirdek ağırlıkları matrisi için başlatıcıdır.\n\npadding-> girdi ve çıktı resmin aynı boyutta olmasını sağlar.\n\nactivation-> ağırlıklı toplamı hesaplayarak ve buna yanlılık ekleyerek bir nöronun etkinleştirilip etkinleştirilmemesi gerektiğine karar verir.","metadata":{}},{"cell_type":"code","source":"def double_conv_block(x,n_filters):\n    \n    x=layers.Conv2D(n_filters,3,padding=\"same\",activation=\"relu\",kernel_initializer=\"he_normal\")(x)\n    x=layers.Conv2D(n_filters,3,padding=\"same\",activation=\"relu\",kernel_initializer=\"he_normal\")(x)\n    return x\n     \n\ndef downsample_block(x,n_filters):\n    f=double_conv_block(x,n_filters)\n    p=layers.MaxPool2D(2)(f)\n    p=layers.Dropout(0.3)(p)\n    return f,p\n\n\ndef upsample_block(x,conv_features,n_filters):\n    \n    \n    \n    x=layers.Conv2DTranspose(n_filters,3,2,padding=\"same\")(x)\n    x=layers.concatenate([x,conv_features])\n    x=layers.Dropout(0.3)(x)\n    x=double_conv_block(x,n_filters)\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:27:09.208145Z","iopub.execute_input":"2022-04-11T18:27:09.20842Z","iopub.status.idle":"2022-04-11T18:27:09.215835Z","shell.execute_reply.started":"2022-04-11T18:27:09.208386Z","shell.execute_reply":"2022-04-11T18:27:09.21501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**build_unet_model()**\n\nYukaridaki fonksiyonları kullanarak istenilen U-Net Modelinin oluşturulduğu fonksiyondur. Aşağıda fonksiyonda verilen parametreler açıklanmıştır.\n\nf1, f2, f3, f4->Convolution katmanı uygulanmıştır.\n\np1,p2,p3,p4->MaxPool2D fonksiyonu ile resmin boyutları ikiye bölünmüştür.\n\nbottleneck->Katmanlarda encode işlemi bittikten ve decode işlemi başlamadan önce oluşan dar boğazdır.\n\nu6, u7, u8, u9->Decode edilen katmanlardır. Bu katmanlara bir önceki decode edilmiş katman ve o sırada denk olan ve daha önceden encode edilmiş (f1,f2,f3,f4) olan katmanlar gönderilerek iki kısmın birleştirilmesi ve sonraki katmanı oluşturması sağlanır.\n\n3->Filtre sayısı\n\n\n1->Convolution katmanının yüksekliği ve genişliği\n\noutputs->Encode ve decode edildikten sonra oluşan katmandır.\n\ncheckpoint ->Model ağırlıklarının kaydedileceği dizindir.\n\ncp_callback->Her 5 epoch'da 1 modelin ağırlıklarını kaydeder.\n\n\nNUM_EPOCHS->Öğrenme algoritmasının tüm eğitim veri kümesi boyunca çalışacağı sayıyı tanımlayan bir hiperparametredir.","metadata":{}},{"cell_type":"code","source":"def build_unet_model():\n\n    inputs=layers.Input(shape=(128,128,3))\n  # encoder: contracting path - downsample\n    f1,p1=downsample_block(inputs,64)\n    f2,p2=downsample_block(p1,128)\n    f3,p3=downsample_block(p2,256)\n    f4,p4=downsample_block(p3,512)\n\n  \n\n    bottleneck=double_conv_block(p4,1024)\n\n  # decoder: expanding path - upsample\n    u6=upsample_block(bottleneck,f4,512)\n    u7=upsample_block(u6,f3,256)\n    u8=upsample_block(u7,f2,128)\n    u9=upsample_block(u8,f1,64)\n\n    outputs=layers.Conv2D(1,1,padding=\"same\",activation = \"sigmoid\")(u9)\n    print(outputs.shape)\n\n    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n    return unet_model\n\n\nBUFFER_SIZE = 100\n\ncheckpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n#Create a callback that saves the model's weights every 5 epochs\ncp_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_path, \n    verbose=1, \n    save_weights_only=True,\n    save_freq=5*200)\n\nunet_model = build_unet_model()\n# Save the weights using the `checkpoint_path` format\nunet_model.save_weights(checkpoint_path.format(epoch=0))\n\n\n\nunet_model.compile(optimizer=tf.keras.optimizers.Adam(),\n                  loss=\"binary_crossentropy\",\n                  metrics=['accuracy'] )\n                \nNUM_EPOCHS = 200\nTRAIN_LENGTH = 9600\n\nVAL_SUBSPLITS = 5\n\nTEST_LENGTH = 1600\n\n\nmodel_history = unet_model.fit(train_dataset,\n                              epochs=NUM_EPOCHS,\n                              callbacks=[cp_callback],\n                              validation_data=test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:39:17.07237Z","iopub.execute_input":"2022-04-11T18:39:17.073157Z","iopub.status.idle":"2022-04-11T18:39:28.449187Z","shell.execute_reply.started":"2022-04-11T18:39:17.073117Z","shell.execute_reply":"2022-04-11T18:39:28.448091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For döngüsü ile eğitilen model üzerinden 100 ve 105 arasında bulunan resimlere maske uygulanmış ve çıktılar alınmıştır.","metadata":{}},{"cell_type":"code","source":"for a in range(100,105):\n    plt.figure(figsize=(10,10))\n    plt.subplot(1,2,1)\n    plt.axis(False)\n    plt.title(\"Original Image\", fontweight=\"bold\")\n    \n    plt.imshow(x[a])\n\n    plt.subplot(1,2,2)\n    plt.axis(False)\n    plt.title(\"Segmentation Mask\", fontweight=\"bold\")\n    img = np.expand_dims(x[a],axis=0)\n    last = unet_model.predict(img)[0,:,:,:]\n    plt.imshow(last * 255.0)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T18:37:27.51372Z","iopub.execute_input":"2022-04-11T18:37:27.513996Z","iopub.status.idle":"2022-04-11T18:37:29.571937Z","shell.execute_reply.started":"2022-04-11T18:37:27.513967Z","shell.execute_reply":"2022-04-11T18:37:29.571309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}